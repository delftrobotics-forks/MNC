name: "ResNet50"
layer {
	name: 'input-data'
	type: 'Python'
	top: 'data'
	top: 'im_info'
	top: 'gt_boxes'
	top: 'gt_masks'
	top: 'mask_info'
	python_param {
		module: 'multitask_network_cascades.pylayer.mnc_data_layer'
		layer: 'MNCDataLayer'
		param_str: "{ 'num_classes': 2 }"
	}
}

# ------------ Convolution -----------

layer {
	bottom: "data"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 7
		pad: 3
		stride: 2
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "scale_conv1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "conv1_relu"
	type: "ReLU"
}

layer {
	bottom: "conv1"
	top: "pool1"
	name: "pool1"
	type: "Pooling"
	pooling_param {
		kernel_size: 3
		stride: 2
		pool: MAX
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch1"
	name: "res2a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch1"
	top: "res2a_branch1"
	name: "bn2a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch1"
	top: "res2a_branch1"
	name: "scale2a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch2a"
	name: "res2a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "bn2a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "scale2a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2a"
	name: "res2a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2b"
	name: "res2a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "bn2a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "scale2a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2b"
	name: "res2a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a_branch2b"
	top: "res2a_branch2c"
	name: "res2a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2c"
	top: "res2a_branch2c"
	name: "bn2a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2a_branch2c"
	top: "res2a_branch2c"
	name: "scale2a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a_branch1"
	bottom: "res2a_branch2c"
	top: "res2a"
	name: "res2a"
	type: "Eltwise"
}

layer {
	bottom: "res2a"
	top: "res2a"
	name: "res2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2a"
	top: "res2b_branch2a"
	name: "res2b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "bn2b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "scale2b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2a"
	name: "res2b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2b"
	name: "res2b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "bn2b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "scale2b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2b"
	name: "res2b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b_branch2b"
	top: "res2b_branch2c"
	name: "res2b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2c"
	top: "res2b_branch2c"
	name: "bn2b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2b_branch2c"
	top: "res2b_branch2c"
	name: "scale2b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2a"
	bottom: "res2b_branch2c"
	top: "res2b"
	name: "res2b"
	type: "Eltwise"
}

layer {
	bottom: "res2b"
	top: "res2b"
	name: "res2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2b"
	top: "res2c_branch2a"
	name: "res2c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "bn2c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "scale2c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2a"
	name: "res2c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2b"
	name: "res2c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "bn2c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "scale2c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2b"
	name: "res2c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c_branch2b"
	top: "res2c_branch2c"
	name: "res2c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2c"
	top: "res2c_branch2c"
	name: "bn2c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res2c_branch2c"
	top: "res2c_branch2c"
	name: "scale2c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2b"
	bottom: "res2c_branch2c"
	top: "res2c"
	name: "res2c"
	type: "Eltwise"
}

layer {
	bottom: "res2c"
	top: "res2c"
	name: "res2c_relu"
	type: "ReLU"
}

layer {
	bottom: "res2c"
	top: "res3a_branch1"
	name: "res3a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch1"
	top: "res3a_branch1"
	name: "bn3a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch1"
	top: "res3a_branch1"
	name: "scale3a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2c"
	top: "res3a_branch2a"
	name: "res3a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "bn3a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "scale3a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2a"
	name: "res3a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2b"
	name: "res3a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "bn3a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "scale3a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2b"
	name: "res3a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a_branch2b"
	top: "res3a_branch2c"
	name: "res3a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2c"
	top: "res3a_branch2c"
	name: "bn3a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3a_branch2c"
	top: "res3a_branch2c"
	name: "scale3a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a_branch1"
	bottom: "res3a_branch2c"
	top: "res3a"
	name: "res3a"
	type: "Eltwise"
}

layer {
	bottom: "res3a"
	top: "res3a"
	name: "res3a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3a"
	top: "res3b_branch2a"
	name: "res3b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "bn3b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "scale3b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2a"
	name: "res3b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b_branch2a"
	top: "res3b_branch2b"
	name: "res3b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "bn3b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "scale3b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2b"
	name: "res3b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b_branch2b"
	top: "res3b_branch2c"
	name: "res3b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b_branch2c"
	top: "res3b_branch2c"
	name: "bn3b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3b_branch2c"
	top: "res3b_branch2c"
	name: "scale3b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3a"
	bottom: "res3b_branch2c"
	top: "res3b"
	name: "res3b"
	type: "Eltwise"
}

layer {
	bottom: "res3b"
	top: "res3b"
	name: "res3b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3b"
	top: "res3c_branch2a"
	name: "res3c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "bn3c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "scale3c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2a"
	name: "res3c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3c_branch2a"
	top: "res3c_branch2b"
	name: "res3c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "bn3c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "scale3c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2b"
	name: "res3c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3c_branch2b"
	top: "res3c_branch2c"
	name: "res3c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3c_branch2c"
	top: "res3c_branch2c"
	name: "bn3c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3c_branch2c"
	top: "res3c_branch2c"
	name: "scale3c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3b"
	bottom: "res3c_branch2c"
	top: "res3c"
	name: "res3c"
	type: "Eltwise"
}

layer {
	bottom: "res3c"
	top: "res3c"
	name: "res3c_relu"
	type: "ReLU"
}

layer {
	bottom: "res3c"
	top: "res3d_branch2a"
	name: "res3d_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "bn3d_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "scale3d_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2a"
	name: "res3d_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res3d_branch2a"
	top: "res3d_branch2b"
	name: "res3d_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "bn3d_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "scale3d_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2b"
	name: "res3d_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res3d_branch2b"
	top: "res3d_branch2c"
	name: "res3d_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3d_branch2c"
	top: "res3d_branch2c"
	name: "bn3d_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res3d_branch2c"
	top: "res3d_branch2c"
	name: "scale3d_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3c"
	bottom: "res3d_branch2c"
	top: "res3d"
	name: "res3d"
	type: "Eltwise"
}

layer {
	bottom: "res3d"
	top: "res3d"
	name: "res3d_relu"
	type: "ReLU"
}

layer {
	bottom: "res3d"
	top: "res4a_branch1"
	name: "res4a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch1"
	top: "res4a_branch1"
	name: "bn4a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch1"
	top: "res4a_branch1"
	name: "scale4a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3d"
	top: "res4a_branch2a"
	name: "res4a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "bn4a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "scale4a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2a"
	name: "res4a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2b"
	name: "res4a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "bn4a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "scale4a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2b"
	name: "res4a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a_branch2b"
	top: "res4a_branch2c"
	name: "res4a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2c"
	top: "res4a_branch2c"
	name: "bn4a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4a_branch2c"
	top: "res4a_branch2c"
	name: "scale4a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a_branch1"
	bottom: "res4a_branch2c"
	top: "res4a"
	name: "res4a"
	type: "Eltwise"
}

layer {
	bottom: "res4a"
	top: "res4a"
	name: "res4a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4a"
	top: "res4b_branch2a"
	name: "res4b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "bn4b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "scale4b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2a"
	name: "res4b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b_branch2a"
	top: "res4b_branch2b"
	name: "res4b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "bn4b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "scale4b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2b"
	name: "res4b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b_branch2b"
	top: "res4b_branch2c"
	name: "res4b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b_branch2c"
	top: "res4b_branch2c"
	name: "bn4b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4b_branch2c"
	top: "res4b_branch2c"
	name: "scale4b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4a"
	bottom: "res4b_branch2c"
	top: "res4b"
	name: "res4b"
	type: "Eltwise"
}

layer {
	bottom: "res4b"
	top: "res4b"
	name: "res4b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4b"
	top: "res4c_branch2a"
	name: "res4c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "bn4c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "scale4c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2a"
	name: "res4c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4c_branch2a"
	top: "res4c_branch2b"
	name: "res4c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "bn4c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "scale4c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2b"
	name: "res4c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4c_branch2b"
	top: "res4c_branch2c"
	name: "res4c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4c_branch2c"
	top: "res4c_branch2c"
	name: "bn4c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4c_branch2c"
	top: "res4c_branch2c"
	name: "scale4c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4b"
	bottom: "res4c_branch2c"
	top: "res4c"
	name: "res4c"
	type: "Eltwise"
}

layer {
	bottom: "res4c"
	top: "res4c"
	name: "res4c_relu"
	type: "ReLU"
}

layer {
	bottom: "res4c"
	top: "res4d_branch2a"
	name: "res4d_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "bn4d_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "scale4d_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2a"
	name: "res4d_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4d_branch2a"
	top: "res4d_branch2b"
	name: "res4d_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "bn4d_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "scale4d_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2b"
	name: "res4d_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4d_branch2b"
	top: "res4d_branch2c"
	name: "res4d_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4d_branch2c"
	top: "res4d_branch2c"
	name: "bn4d_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4d_branch2c"
	top: "res4d_branch2c"
	name: "scale4d_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4c"
	bottom: "res4d_branch2c"
	top: "res4d"
	name: "res4d"
	type: "Eltwise"
}

layer {
	bottom: "res4d"
	top: "res4d"
	name: "res4d_relu"
	type: "ReLU"
}

layer {
	bottom: "res4d"
	top: "res4e_branch2a"
	name: "res4e_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "bn4e_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "scale4e_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2a"
	name: "res4e_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4e_branch2a"
	top: "res4e_branch2b"
	name: "res4e_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "bn4e_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "scale4e_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2b"
	name: "res4e_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4e_branch2b"
	top: "res4e_branch2c"
	name: "res4e_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4e_branch2c"
	top: "res4e_branch2c"
	name: "bn4e_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4e_branch2c"
	top: "res4e_branch2c"
	name: "scale4e_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4d"
	bottom: "res4e_branch2c"
	top: "res4e"
	name: "res4e"
	type: "Eltwise"
}

layer {
	bottom: "res4e"
	top: "res4e"
	name: "res4e_relu"
	type: "ReLU"
}

layer {
	bottom: "res4e"
	top: "res4f_branch2a"
	name: "res4f_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "bn4f_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "scale4f_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2a"
	name: "res4f_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res4f_branch2a"
	top: "res4f_branch2b"
	name: "res4f_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "bn4f_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "scale4f_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2b"
	name: "res4f_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res4f_branch2b"
	top: "res4f_branch2c"
	name: "res4f_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4f_branch2c"
	top: "res4f_branch2c"
	name: "bn4f_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res4f_branch2c"
	top: "res4f_branch2c"
	name: "scale4f_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res4e"
	bottom: "res4f_branch2c"
	top: "res4f"
	name: "res4f"
	type: "Eltwise"
}

layer {
	bottom: "res4f"
	top: "res4f"
	name: "res4f_relu"
	type: "ReLU"
}

#------------ RPN ------------

layer {
	name: "rpn_conv_3x3"
	type: "Convolution"
	bottom: "res4f"
	top: "rpn_output"
	param { lr_mult: 1.0 }
	param { lr_mult: 2.0 }
	convolution_param {
		num_output: 512
		kernel_size: 3 pad: 1 stride: 1
		weight_filler { type: "gaussian" std: 0.01 }
		bias_filler { type: "constant" value: 0 }
	}
}

layer {
	name: "rpn_relu_3x3"
	type: "ReLU"
	bottom: "rpn_output"
	top: "rpn_output"
}

layer {
	name: "rpn_cls_score"
	type: "Convolution"
	bottom: "rpn_output"
	top: "rpn_cls_score"
	param { lr_mult: 1.0 }
	param { lr_mult: 2.0 }
	convolution_param {
		num_output: 18   # 2(bg/fg) * 9(anchors)
		kernel_size: 1 pad: 0 stride: 1
		weight_filler { type: "gaussian" std: 0.01 }
		bias_filler { type: "constant" value: 0 }
	}
}

layer {
	name: "rpn_bbox_pred"
	type: "Convolution"
	bottom: "rpn_output"
	top: "rpn_bbox_pred"
	param { lr_mult: 1.0 }
	param { lr_mult: 2.0 }
	convolution_param {
		num_output: 36   # 4 * 9(anchors)
		kernel_size: 1 pad: 0 stride: 1
		weight_filler { type: "gaussian" std: 0.01 }
		bias_filler { type: "constant" value: 0 }
	}
}

layer {
	 bottom: "rpn_cls_score"
	 top: "rpn_cls_score_reshape"
	 name: "rpn_cls_score_reshape"
	 type: "Reshape"
	 reshape_param { shape { dim: 0 dim: 2 dim: -1 dim: 0 } }
}

#------------ Anchor to Proposal ------------

layer {
	name: "rpn_cls_prob"
	type: "Softmax"
	bottom: "rpn_cls_score_reshape"
	top: "rpn_cls_prob"
}

layer {
	name: 'rpn_cls_prob_reshape'
	type: 'Reshape'
	bottom: 'rpn_cls_prob'
	top: 'rpn_cls_prob_reshape'
	reshape_param { shape { dim: 0 dim: 18 dim: -1 dim: 0 } }
}

layer {
	name: 'proposal'
	type: 'Python'
	bottom: 'rpn_cls_prob_reshape'
	bottom: 'rpn_bbox_pred'
	bottom: 'im_info'
	propagate_down: 0
	propagate_down: 1
	propagate_down: 0
	top: 'rpn_rois'
	top: 'rpn_rois_index'
	python_param {
		module: 'multitask_network_cascades.pylayer.proposal_layer'
		layer: 'ProposalLayer'
		param_str: "{ 'feat_stride': 16, 'use_clip': 1, 'clip_base': 512 }"
	}
}

layer {
	name: 'roi-data'
	type: 'Python'
	bottom: 'rpn_rois'
	bottom: 'gt_boxes'
	bottom: 'im_info'
	bottom: 'gt_masks'
	bottom: 'mask_info'
	bottom: 'rpn_rois_index'
	propagate_down: 1
	propagate_down: 0
	propagate_down: 0
	propagate_down: 0
	propagate_down: 0
	propagate_down: 0
	top: 'rois'
	top: 'labels'
	top: 'bbox_targets'
	top: 'bbox_inside_weights'
	top: 'bbox_outside_weights'
	top: 'mask_targets'
	top: 'mask_weight'
	top: 'gt_masks_info'
	top: 'fg_inds'
	top: 'bg_inds'
	python_param {
		module: 'multitask_network_cascades.pylayer.proposal_target_layer'
		layer: 'ProposalTargetLayer'
		param_str: "{'num_classes': 2, 'bp_all': 1}"
	}
}

layer {
	name: 'rpn-data'
	type: 'Python'
	bottom: 'rpn_cls_score'
	bottom: 'gt_boxes'
	bottom: 'im_info'
	bottom: 'fg_inds'
	bottom: 'bg_inds'
	top: 'rpn_labels'
	top: 'rpn_bbox_targets'
	top: 'rpn_bbox_inside_weights'
	top: 'rpn_bbox_outside_weights'
	python_param {
		module: 'multitask_network_cascades.pylayer.anchor_target_layer'
		layer: 'AnchorTargetLayer'
		param_str: "{'feat_stride': 16}"
	}
}

#------------ RPN loss ------------
# put rpn loss here since we need
# proposal's index first

layer {
	name: "rpn_loss_cls"
	type: "SoftmaxWithLoss"
	bottom: "rpn_cls_score_reshape"
	bottom: "rpn_labels"
	propagate_down: 1
	propagate_down: 0
	top: "rpn_cls_loss"
	loss_weight: 1
	loss_param {
		ignore_label: -1
		normalize: true
	}
}

layer {
	name: "rpn_loss_bbox"
	type: "Module"
	bottom: "rpn_bbox_pred"
	bottom: "rpn_bbox_targets"
	bottom: 'rpn_bbox_inside_weights'
	bottom: 'rpn_bbox_outside_weights'
	top: "rpn_loss_bbox"
	loss_weight: 1
	module_param {
		module: "mnc"
		type: "SmoothL1Loss"
		param_str: "{ 'sigma': 3 }"
	}
}

#------------ Roi Warping ------------

layer {
	name: "roi_interpolate_conv5"
	type: "Module"
	bottom: "res4f"
	bottom: "rois"
	propagate_down: 1
	propagate_down: 1
	top: "roi_interpolate_conv5"
	module_param {
		module: "mnc"
		type: "ROIWarping"
		param_str: "{ 'pooled_w': 14, 'pooled_h': 14, 'spatial_scale': 0.0625 }"
	}
}

#------------ Mask Estimation ------------

layer {
	name: "fc6_maskest"
	type: "InnerProduct"
	bottom: "roi_interpolate_conv5"
	top: "fc6_maskest"
	param {
		name: "fc6_maskest_w" 
		lr_mult: 1.0 
	}
	param {
		name: "fc6_maskest_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 256
		weight_filler {
			type: "gaussian"
			std: 0.001
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "relu6_maskest"
	type: "ReLU"
	bottom: "fc6_maskest"
	top: "fc6_maskest"
}

layer {
	name: "mask_pred"
	type: "InnerProduct"
	bottom: "fc6_maskest"
	top: "mask_pred"
	param {
		name: "mask_pred_w" 
		lr_mult: 1.0 
	}
	param {
		name: "mask_pred_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 441 # 21 * 21
		weight_filler {
			type: "gaussian"
			std: 0.001
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_mask"
	type: "Module"
	bottom: "mask_pred"
	bottom: "mask_targets"
	bottom: "mask_weight"
	propagate_down: 1
	propagate_down: 0
	propagate_down: 0
	top: "loss_mask"
	loss_weight: 2
	module_param {
		module: "mnc"
		type: "SigmoidCrossEntropyLoss"
	}
}

#------------ Mask resize ------------
# get masks from sigmoid prediction 
# and use it for mask pooling

layer {
	name: "mask_output"
	type: "Sigmoid"
	bottom: "mask_pred"
	top: "mask_output"
}

layer {
	name: "mask_proposal"
	type: 'Python'
	bottom: 'mask_output'
	bottom: 'gt_masks'
	bottom: 'gt_masks_info'
	propagate_down: 1
	propagate_down: 0
	propagate_down: 0
	top: 'mask_proposal'
	top: 'mask_proposal_label'
	python_param {
		module: 'multitask_network_cascades.pylayer.mask_layer'
		layer: 'MaskLayer'
	}
}

layer {
	name: "mask_resize"
	type: "Module"
	bottom: "mask_proposal"
	top: "mask_proposal_resize"
	module_param {
		module: "mnc"
		type: "MaskResize"
		param_str: "{ 'output_width': 14, 'output_height': 14 }"
	}
}

#------------ Box Features ------------

layer {
	name: "roi_interpolate_conv5_box"
	type: "Pooling"
	bottom: "roi_interpolate_conv5"
	top: "roi_interpolate_conv5_box"
	pooling_param {
		kernel_size: 2
		stride: 1
		pad: 0
		pool: MAX
	}
}

layer {
	bottom: "roi_interpolate_conv5_box"
	top: "res5a_branch1"
	name: "res5a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch1"
	top: "res5a_branch1"
	name: "bn5a_branch1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch1"
	top: "res5a_branch1"
	name: "scale5a_branch1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "roi_interpolate_conv5_box"
	top: "res5a_branch2a"
	name: "res5a_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "bn5a_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "scale5a_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2a"
	name: "res5a_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2b"
	name: "res5a_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "bn5a_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "scale5a_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2b"
	name: "res5a_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2b"
	top: "res5a_branch2c"
	name: "res5a_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2c"
	top: "res5a_branch2c"
	name: "bn5a_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2c"
	top: "res5a_branch2c"
	name: "scale5a_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch1"
	bottom: "res5a_branch2c"
	top: "res5a"
	name: "res5a"
	type: "Eltwise"
}

layer {
	bottom: "res5a"
	top: "res5a"
	name: "res5a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5a"
	top: "res5b_branch2a"
	name: "res5b_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "bn5b_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "scale5b_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2a"
	name: "res5b_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2b"
	name: "res5b_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "bn5b_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "scale5b_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2b"
	name: "res5b_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2b"
	top: "res5b_branch2c"
	name: "res5b_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2c"
	top: "res5b_branch2c"
	name: "bn5b_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2c"
	top: "res5b_branch2c"
	name: "scale5b_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a"
	bottom: "res5b_branch2c"
	top: "res5b"
	name: "res5b"
	type: "Eltwise"
}

layer {
	bottom: "res5b"
	top: "res5b"
	name: "res5b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5b"
	top: "res5c_branch2a"
	name: "res5c_branch2a"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "bn5c_branch2a"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "scale5c_branch2a"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2a"
	name: "res5c_branch2a_relu"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2b"
	name: "res5c_branch2b"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "bn5c_branch2b"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "scale5c_branch2b"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2b"
	name: "res5c_branch2b_relu"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2b"
	top: "res5c_branch2c"
	name: "res5c_branch2c"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2c"
	top: "res5c_branch2c"
	name: "bn5c_branch2c"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2c"
	top: "res5c_branch2c"
	name: "scale5c_branch2c"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b"
	bottom: "res5c_branch2c"
	top: "res5c"
	name: "res5c"
	type: "Eltwise"
}

layer {
	bottom: "res5c"
	top: "res5c"
	name: "res5c_relu"
	type: "ReLU"
}

layer {
	bottom: "res5c"
	top: "pool5"
	name: "pool5"
	type: "Pooling"
	pooling_param {
		kernel_size: 7
		stride: 1
		pool: AVE
	}
}

#------------ Mask Features ------------

layer {
	name: "mask_pooling"
	type: "Module"
	propagate_down: 1
	propagate_down: 1
	bottom: "roi_interpolate_conv5"
	bottom: "mask_proposal_resize"
	top: "roi_mask_conv5"
	module_param {
		module: "mnc"
		type: "MaskPooling"
	}
}

layer {
	name: "roi_interpolate_conv5_mask"
	type: "Pooling"
	bottom: "roi_mask_conv5"
	top: "roi_interpolate_conv5_mask"
	pooling_param {
		kernel_size: 2
		stride: 1
		pad: 0
		pool: MAX
	}
}

layer {
	bottom: "roi_interpolate_conv5_mask"
	top: "res5a_branch1_mask"
	name: "res5a_branch1_mask"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch1_mask"
	top: "res5a_branch1_mask"
	name: "bn5a_branch1_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch1_mask"
	top: "res5a_branch1_mask"
	name: "scale5a_branch1_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "roi_interpolate_conv5_mask"
	top: "res5a_branch2a_mask"
	name: "res5a_branch2a_mask"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a_mask"
	top: "res5a_branch2a_mask"
	name: "bn5a_branch2a_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2a_mask"
	top: "res5a_branch2a_mask"
	name: "scale5a_branch2a_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2a_mask"
	top: "res5a_branch2a_mask"
	name: "res5a_branch2a_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2a_mask"
	top: "res5a_branch2b_mask"
	name: "res5a_branch2b_mask"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b_mask"
	top: "res5a_branch2b_mask"
	name: "bn5a_branch2b_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2b_mask"
	top: "res5a_branch2b_mask"
	name: "scale5a_branch2b_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2b_mask"
	top: "res5a_branch2b_mask"
	name: "res5a_branch2b_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2b_mask"
	top: "res5a_branch2c_mask"
	name: "res5a_branch2c_mask"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2c_mask"
	top: "res5a_branch2c_mask"
	name: "bn5a_branch2c_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2c_mask"
	top: "res5a_branch2c_mask"
	name: "scale5a_branch2c_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch1_mask"
	bottom: "res5a_branch2c_mask"
	top: "res5a_mask"
	name: "res5a_mask"
	type: "Eltwise"
}

layer {
	bottom: "res5a_mask"
	top: "res5a_mask"
	name: "res5a_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5a_mask"
	top: "res5b_branch2a_mask"
	name: "res5b_branch2a_mask"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a_mask"
	top: "res5b_branch2a_mask"
	name: "bn5b_branch2a_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2a_mask"
	top: "res5b_branch2a_mask"
	name: "scale5b_branch2a_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2a_mask"
	top: "res5b_branch2a_mask"
	name: "res5b_branch2a_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2a_mask"
	top: "res5b_branch2b_mask"
	name: "res5b_branch2b_mask"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b_mask"
	top: "res5b_branch2b_mask"
	name: "bn5b_branch2b_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2b_mask"
	top: "res5b_branch2b_mask"
	name: "scale5b_branch2b_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2b_mask"
	top: "res5b_branch2b_mask"
	name: "res5b_branch2b_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2b_mask"
	top: "res5b_branch2c_mask"
	name: "res5b_branch2c_mask"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2c_mask"
	top: "res5b_branch2c_mask"
	name: "bn5b_branch2c_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2c_mask"
	top: "res5b_branch2c_mask"
	name: "scale5b_branch2c_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_mask"
	bottom: "res5b_branch2c_mask"
	top: "res5b_mask"
	name: "res5b_mask"
	type: "Eltwise"
}

layer {
	bottom: "res5b_mask"
	top: "res5b_mask"
	name: "res5b_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5b_mask"
	top: "res5c_branch2a_mask"
	name: "res5c_branch2a_mask"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a_mask"
	top: "res5c_branch2a_mask"
	name: "bn5c_branch2a_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2a_mask"
	top: "res5c_branch2a_mask"
	name: "scale5c_branch2a_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2a_mask"
	top: "res5c_branch2a_mask"
	name: "res5c_branch2a_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2a_mask"
	top: "res5c_branch2b_mask"
	name: "res5c_branch2b_mask"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b_mask"
	top: "res5c_branch2b_mask"
	name: "bn5c_branch2b_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2b_mask"
	top: "res5c_branch2b_mask"
	name: "scale5c_branch2b_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2b_mask"
	top: "res5c_branch2b_mask"
	name: "res5c_branch2b_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2b_mask"
	top: "res5c_branch2c_mask"
	name: "res5c_branch2c_mask"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2c_mask"
	top: "res5c_branch2c_mask"
	name: "bn5c_branch2c_mask"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2c_mask"
	top: "res5c_branch2c_mask"
	name: "scale5c_branch2c_mask"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_mask"
	bottom: "res5c_branch2c_mask"
	top: "res5c_mask"
	name: "res5c_mask"
	type: "Eltwise"
}

layer {
	bottom: "res5c_mask"
	top: "res5c_mask"
	name: "res5c_relu_mask"
	type: "ReLU"
}

layer {
	bottom: "res5c_mask"
	top: "pool5_mask"
	name: "pool5_mask"
	type: "Pooling"
	pooling_param {
		kernel_size: 7
		stride: 1
		pool: AVE
	}
}

#----- Concat Box-Mask Feature -----

layer {
	name: "join_box_mask"
	type: "Concat"
	bottom: "pool5_mask"
	bottom: "pool5"
	top: "join_box_mask"
	concat_param {
		axis: 1
	}
}

#----- Box-level Classification -----

layer {
	name: "cls_score"
	type: "InnerProduct"
	bottom: "join_box_mask"
	top: "cls_score"
	param {
		name: "cls_score_w" 
		lr_mult: 1.0 
	}
	param {
		name: "cls_score_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 2
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_cls"
	type: "SoftmaxWithLoss"
	bottom: "cls_score"
	bottom: "labels"
	propagate_down: 1
	propagate_down: 0
	top: "cls_loss"
	loss_weight: 1
	loss_param {
		ignore_label: -1
		normalize: true
	}
}

#----- Mask-level Classification -----

layer {
	name: "seg_cls_score"
	type: "InnerProduct"
	bottom: "join_box_mask"
	top: "seg_cls_score"
	param {
		name: "seg_cls_score_w" 
		lr_mult: 1.0 
	}
	param {
		name: "seg_cls_score_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 2
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_seg_cls"
	type: "SoftmaxWithLoss"
	bottom: "seg_cls_score"
	bottom: "mask_proposal_label"
	propagate_down: 1
	propagate_down: 0
	top: "seg_cls_loss"
	loss_weight: 1.0
	loss_param {
		ignore_label: -1
		normalize: true
	}
}

#----- Bounding-box Regression -----

layer {
	name: "bbox_pred"
	type: "InnerProduct"
	bottom: "join_box_mask"
	top: "bbox_pred"
	param {
		name: "bbox_pred_w" 
		lr_mult: 1.0 
	}
	param {
		name: "bbox_pred_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 8
		weight_filler {
			type: "gaussian"
			std: 0.001
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_bbox"
	type: "Module"
	bottom: "bbox_pred"
	bottom: "bbox_targets"
	bottom: 'bbox_inside_weights'
	bottom: 'bbox_outside_weights'
	top: "bbox_loss"
	loss_weight: 1
	module_param {
		module: "mnc"
		type: "SmoothL1Loss"
		param_str: "{ 'sigma': 1 }"
	}
}

layer {
	name: "accuracy_seg"
	type: "Accuracy"
	bottom: "seg_cls_score"
	bottom: "mask_proposal_label"
	top: "accuracy_seg"
}

layer {
	name: "accuracy_det"
	type: "Accuracy"
	bottom: "cls_score"
	bottom: "labels"
	top: "accuracy_det"
}

# --------- Next Stage ----------
# We extend 3 stage mnc to 5 stage
# layer structure are mostly similar
# name are suffixed by _ext (extend)

layer {
	name: "seg_cls_prob"
	type: "Softmax"
	bottom: "seg_cls_score"
	top: "seg_cls_prob"
	loss_param {
		ignore_label: -1
		normalize: true
	}
}

layer {
	name: "stage_bridge"
	type: 'Python'
	bottom: 'rois'
	bottom: 'bbox_pred'
	bottom: 'seg_cls_prob'
	bottom: 'gt_boxes'
	bottom: 'gt_masks'
	bottom: 'im_info'
	bottom: 'mask_info'
	propagate_down: 1
	propagate_down: 1
	propagate_down: 0
	propagate_down: 0
	propagate_down: 0
	propagate_down: 0
	propagate_down: 0
	top: 'rois_ext'
	top: 'labels_ext'
	top: 'mask_targets_ext'
	top: 'mask_weight_ext'
	top: 'gt_masks_info_ext'
	top: 'bbox_targets_ext'
	top: 'bbox_inside_weights_ext'
	top: 'bbox_outside_weights_ext'
	python_param {
		module: 'multitask_network_cascades.pylayer.stage_bridge_layer'
		layer: 'StageBridgeLayer'
		param_str: "{ 'feat_stride': 16, 'use_clip': 1, 'clip_base': 512 }"
	}
}

#------------ Roi Warping Ext ------------

layer {
	name: "roi_interpolate_conv5_ext"
	type: "Module"
	bottom: "res4f"
	bottom: "rois_ext"
	propagate_down: 1
	propagate_down: 1
	top: "roi_interpolate_conv5_ext"
	module_param {
		module: "mnc"
		type: "ROIWarping"
		param_str: "{ 'pooled_w': 14, 'pooled_h': 14, 'spatial_scale': 0.0625 }"
	}
}

#------------ Mask Estimation Ext ------------

layer {
	name: "fc6_maskest_ext"
	type: "InnerProduct"
	bottom: "roi_interpolate_conv5_ext"
	top: "fc6_maskest_ext"
	param {
		name: "fc6_maskest_w" 
		lr_mult: 1.0 
	}
	param {
		name: "fc6_maskest_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 256
		weight_filler {
			type: "gaussian"
			std: 0.001
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "relu6_maskest_ext"
	type: "ReLU"
	bottom: "fc6_maskest_ext"
	top: "fc6_maskest_ext"
}

layer {
	name: "mask_pred_ext"
	type: "InnerProduct"
	bottom: "fc6_maskest_ext"
	top: "mask_pred_ext"
	param {
		name: "mask_pred_w" 
		lr_mult: 1.0 
	}
	param {
		name: "mask_pred_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 441 # 21 * 21
		weight_filler {
			type: "gaussian"
			std: 0.001
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_mask_ext"
	type: "Module"
	bottom: "mask_pred_ext"
	bottom: "mask_targets_ext"
	bottom: "mask_weight_ext"
	propagate_down: 1
	propagate_down: 0
	propagate_down: 0
	top: "loss_mask_ext"
	loss_weight: 2
	module_param {
		module: "mnc"
		type: "SigmoidCrossEntropyLoss"
	}
}

#------------ Mask Resize ------------
# get masks from sigmoid prediction 
# and use it for mask pooling

layer {
	name: "mask_output_ext"
	type: "Sigmoid"
	bottom: "mask_pred_ext"
	top: "mask_output_ext"
}

layer {
	name: "mask_proposal_ext"
	type: 'Python'
	bottom: 'mask_output_ext'
	bottom: 'gt_masks'
	bottom: 'gt_masks_info_ext'
	propagate_down: 1
	propagate_down: 0
	propagate_down: 0
	top: 'mask_proposal_ext'
	top: 'mask_proposal_label_ext'
	python_param {
		module: 'multitask_network_cascades.pylayer.mask_layer'
		layer: 'MaskLayer'
	}
}

layer {
	name: "mask_resize_ext"
	type: "Module"
	bottom: "mask_proposal_ext"
	top: "mask_proposal_resize_ext"
	module_param {
		module: "mnc"
		type: "MaskResize"
		param_str: "{ 'output_width': 14, 'output_height': 14 }"
	}
}

#------------ Box Features Ext ------------

layer {
	name: "roi_interpolate_conv5_box_ext"
	type: "Pooling"
	bottom: "roi_interpolate_conv5_ext"
	top: "roi_interpolate_conv5_box_ext"
	pooling_param {
		kernel_size: 2
		stride: 1
		pad: 0
		pool: MAX
	}
}

layer {
	bottom: "roi_interpolate_conv5_box_ext"
	top: "res5a_branch1_ext"
	name: "res5a_branch1_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch1_ext"
	top: "res5a_branch1_ext"
	name: "bn5a_branch1_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch1_ext"
	top: "res5a_branch1_ext"
	name: "scale5a_branch1_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "roi_interpolate_conv5_box_ext"
	top: "res5a_branch2a_ext"
	name: "res5a_branch2a_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a_ext"
	top: "res5a_branch2a_ext"
	name: "bn5a_branch2a_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2a_ext"
	top: "res5a_branch2a_ext"
	name: "scale5a_branch2a_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2a_ext"
	top: "res5a_branch2a_ext"
	name: "res5a_branch2a_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2a_ext"
	top: "res5a_branch2b_ext"
	name: "res5a_branch2b_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b_ext"
	top: "res5a_branch2b_ext"
	name: "bn5a_branch2b_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2b_ext"
	top: "res5a_branch2b_ext"
	name: "scale5a_branch2b_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2b_ext"
	top: "res5a_branch2b_ext"
	name: "res5a_branch2b_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2b_ext"
	top: "res5a_branch2c_ext"
	name: "res5a_branch2c_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2c_ext"
	top: "res5a_branch2c_ext"
	name: "bn5a_branch2c_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2c_ext"
	top: "res5a_branch2c_ext"
	name: "scale5a_branch2c_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch1_ext"
	bottom: "res5a_branch2c_ext"
	top: "res5a_ext"
	name: "res5a_ext"
	type: "Eltwise"
}

layer {
	bottom: "res5a_ext"
	top: "res5a_ext"
	name: "res5a_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5a_ext"
	top: "res5b_branch2a_ext"
	name: "res5b_branch2a_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a_ext"
	top: "res5b_branch2a_ext"
	name: "bn5b_branch2a_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2a_ext"
	top: "res5b_branch2a_ext"
	name: "scale5b_branch2a_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2a_ext"
	top: "res5b_branch2a_ext"
	name: "res5b_branch2a_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2a_ext"
	top: "res5b_branch2b_ext"
	name: "res5b_branch2b_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b_ext"
	top: "res5b_branch2b_ext"
	name: "bn5b_branch2b_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2b_ext"
	top: "res5b_branch2b_ext"
	name: "scale5b_branch2b_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2b_ext"
	top: "res5b_branch2b_ext"
	name: "res5b_branch2b_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2b_ext"
	top: "res5b_branch2c_ext"
	name: "res5b_branch2c_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2c_ext"
	top: "res5b_branch2c_ext"
	name: "bn5b_branch2c_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2c_ext"
	top: "res5b_branch2c_ext"
	name: "scale5b_branch2c_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_ext"
	bottom: "res5b_branch2c_ext"
	top: "res5b_ext"
	name: "res5b_ext"
	type: "Eltwise"
}

layer {
	bottom: "res5b_ext"
	top: "res5b_ext"
	name: "res5b_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5b_ext"
	top: "res5c_branch2a_ext"
	name: "res5c_branch2a_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a_ext"
	top: "res5c_branch2a_ext"
	name: "bn5c_branch2a_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2a_ext"
	top: "res5c_branch2a_ext"
	name: "scale5c_branch2a_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2a_ext"
	top: "res5c_branch2a_ext"
	name: "res5c_branch2a_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2a_ext"
	top: "res5c_branch2b_ext"
	name: "res5c_branch2b_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b_ext"
	top: "res5c_branch2b_ext"
	name: "bn5c_branch2b_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2b_ext"
	top: "res5c_branch2b_ext"
	name: "scale5c_branch2b_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2b_ext"
	top: "res5c_branch2b_ext"
	name: "res5c_branch2b_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2b_ext"
	top: "res5c_branch2c_ext"
	name: "res5c_branch2c_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2c_ext"
	top: "res5c_branch2c_ext"
	name: "bn5c_branch2c_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2c_ext"
	top: "res5c_branch2c_ext"
	name: "scale5c_branch2c_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_ext"
	bottom: "res5c_branch2c_ext"
	top: "res5c_ext"
	name: "res5c_ext"
	type: "Eltwise"
}

layer {
	bottom: "res5c_ext"
	top: "res5c_ext"
	name: "res5c_relu_ext"
	type: "ReLU"
}

layer {
	bottom: "res5c_ext"
	top: "pool5_ext"
	name: "pool5_ext"
	type: "Pooling"
	pooling_param {
		kernel_size: 7
		stride: 1
		pool: AVE
	}
}

# ------ Mask Feature Ext ---------

layer {
	name: "mask_pooling_ext"
	type: "Module"
	propagate_down: 1
	propagate_down: 1
	bottom: "roi_interpolate_conv5_ext"
	bottom: "mask_proposal_resize_ext"
	top: "roi_mask_conv5_ext"
	module_param {
		module: "mnc"
		type: "MaskPooling"
	}
}

layer {
	name: "roi_interpolate_conv5_mask_ext"
	type: "Pooling"
	bottom: "roi_mask_conv5_ext"
	top: "roi_interpolate_conv5_mask_ext"
	pooling_param {
		kernel_size: 2
		stride: 1
		pad: 0
		pool: MAX
	}
}

layer {
	bottom: "roi_interpolate_conv5_mask_ext"
	top: "res5a_branch1_mask_ext"
	name: "res5a_branch1_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch1_mask_ext"
	top: "res5a_branch1_mask_ext"
	name: "bn5a_branch1_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch1_mask_ext"
	top: "res5a_branch1_mask_ext"
	name: "scale5a_branch1_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "roi_interpolate_conv5_mask_ext"
	top: "res5a_branch2a_mask_ext"
	name: "res5a_branch2a_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a_mask_ext"
	top: "res5a_branch2a_mask_ext"
	name: "bn5a_branch2a_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2a_mask_ext"
	top: "res5a_branch2a_mask_ext"
	name: "scale5a_branch2a_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2a_mask_ext"
	top: "res5a_branch2a_mask_ext"
	name: "res5a_branch2a_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2a_mask_ext"
	top: "res5a_branch2b_mask_ext"
	name: "res5a_branch2b_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b_mask_ext"
	top: "res5a_branch2b_mask_ext"
	name: "bn5a_branch2b_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2b_mask_ext"
	top: "res5a_branch2b_mask_ext"
	name: "scale5a_branch2b_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch2b_mask_ext"
	top: "res5a_branch2b_mask_ext"
	name: "res5a_branch2b_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5a_branch2b_mask_ext"
	top: "res5a_branch2c_mask_ext"
	name: "res5a_branch2c_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2c_mask_ext"
	top: "res5a_branch2c_mask_ext"
	name: "bn5a_branch2c_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5a_branch2c_mask_ext"
	top: "res5a_branch2c_mask_ext"
	name: "scale5a_branch2c_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_branch1_mask_ext"
	bottom: "res5a_branch2c_mask_ext"
	top: "res5a_mask_ext"
	name: "res5a_mask_ext"
	type: "Eltwise"
}

layer {
	bottom: "res5a_mask_ext"
	top: "res5a_mask_ext"
	name: "res5a_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5a_mask_ext"
	top: "res5b_branch2a_mask_ext"
	name: "res5b_branch2a_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a_mask_ext"
	top: "res5b_branch2a_mask_ext"
	name: "bn5b_branch2a_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2a_mask_ext"
	top: "res5b_branch2a_mask_ext"
	name: "scale5b_branch2a_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2a_mask_ext"
	top: "res5b_branch2a_mask_ext"
	name: "res5b_branch2a_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2a_mask_ext"
	top: "res5b_branch2b_mask_ext"
	name: "res5b_branch2b_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b_mask_ext"
	top: "res5b_branch2b_mask_ext"
	name: "bn5b_branch2b_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2b_mask_ext"
	top: "res5b_branch2b_mask_ext"
	name: "scale5b_branch2b_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_branch2b_mask_ext"
	top: "res5b_branch2b_mask_ext"
	name: "res5b_branch2b_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5b_branch2b_mask_ext"
	top: "res5b_branch2c_mask_ext"
	name: "res5b_branch2c_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2c_mask_ext"
	top: "res5b_branch2c_mask_ext"
	name: "bn5b_branch2c_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5b_branch2c_mask_ext"
	top: "res5b_branch2c_mask_ext"
	name: "scale5b_branch2c_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5a_mask_ext"
	bottom: "res5b_branch2c_mask_ext"
	top: "res5b_mask_ext"
	name: "res5b_mask_ext"
	type: "Eltwise"
}

layer {
	bottom: "res5b_mask_ext"
	top: "res5b_mask_ext"
	name: "res5b_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5b_mask_ext"
	top: "res5c_branch2a_mask_ext"
	name: "res5c_branch2a_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a_mask_ext"
	top: "res5c_branch2a_mask_ext"
	name: "bn5c_branch2a_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2a_mask_ext"
	top: "res5c_branch2a_mask_ext"
	name: "scale5c_branch2a_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2a_mask_ext"
	top: "res5c_branch2a_mask_ext"
	name: "res5c_branch2a_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2a_mask_ext"
	top: "res5c_branch2b_mask_ext"
	name: "res5c_branch2b_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b_mask_ext"
	top: "res5c_branch2b_mask_ext"
	name: "bn5c_branch2b_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2b_mask_ext"
	top: "res5c_branch2b_mask_ext"
	name: "scale5c_branch2b_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5c_branch2b_mask_ext"
	top: "res5c_branch2b_mask_ext"
	name: "res5c_branch2b_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5c_branch2b_mask_ext"
	top: "res5c_branch2c_mask_ext"
	name: "res5c_branch2c_mask_ext"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2c_mask_ext"
	top: "res5c_branch2c_mask_ext"
	name: "bn5c_branch2c_mask_ext"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
}

layer {
	bottom: "res5c_branch2c_mask_ext"
	top: "res5c_branch2c_mask_ext"
	name: "scale5c_branch2c_mask_ext"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res5b_mask_ext"
	bottom: "res5c_branch2c_mask_ext"
	top: "res5c_mask_ext"
	name: "res5c_mask_ext"
	type: "Eltwise"
}

layer {
	bottom: "res5c_mask_ext"
	top: "res5c_mask_ext"
	name: "res5c_relu_mask_ext"
	type: "ReLU"
}

layer {
	bottom: "res5c_mask_ext"
	top: "pool5_mask_ext"
	name: "pool5_mask_ext"
	type: "Pooling"
	pooling_param {
		kernel_size: 7
		stride: 1
		pool: AVE
	}
}

#----- Concat Box-Mask Feature -----

layer {
	name: "join_box_mask_ext"
	type: "Concat"
	bottom: "pool5_mask_ext"
	bottom: "pool5_ext"
	top: "join_box_mask_ext"
	concat_param {
		axis: 1
	}
}

#----- Box-level Classification -----

layer {
	name: "cls_score_ext"
	type: "InnerProduct"
	bottom: "join_box_mask_ext"
	top: "cls_score_ext"
	param {
		name: "cls_score_w" 
		lr_mult: 1.0 
	}
	param {
		name: "cls_score_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 2
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_cls_ext"
	type: "SoftmaxWithLoss"
	bottom: "cls_score_ext"
	bottom: "labels_ext"
	propagate_down: 1
	propagate_down: 0
	top: "cls_loss_ext"
	loss_weight: 1
	loss_param {
		ignore_label: -1
		normalize: true
	}
}

#----- Mask-level Classification -----

layer {
	name: "seg_cls_score_ext"
	type: "InnerProduct"
	bottom: "join_box_mask_ext"
	top: "seg_cls_score_ext"
	param {
		name: "seg_cls_score_w" 
		lr_mult: 1.0 
	}
	param {
		name: "seg_cls_score_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 2
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_seg_cls_ext"
	type: "SoftmaxWithLoss"
	bottom: "seg_cls_score_ext"
	bottom: "mask_proposal_label_ext"
	propagate_down: 1
	propagate_down: 0
	top: "seg_cls_loss_ext"
	loss_weight: 1
	loss_param {
		ignore_label: -1
		normalize: true
	}
}

#----- Bounding-box Regression -----

layer {
	name: "bbox_pred_ext"
	type: "InnerProduct"
	bottom: "join_box_mask_ext"
	top: "bbox_pred_ext"
	param {
		name: "bbox_pred_w" 
		lr_mult: 1.0 
	}
	param {
		name: "bbox_pred_b" 
		lr_mult: 2.0 
	}
	inner_product_param {
		num_output: 8
		weight_filler {
			type: "gaussian"
			std: 0.001
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "loss_bbox_ext"
	type: "Module"
	bottom: "bbox_pred_ext"
	bottom: "bbox_targets_ext"
	bottom: 'bbox_inside_weights_ext'
	bottom: 'bbox_outside_weights_ext'
	top: "bbox_loss_ext"
	loss_weight: 1
	module_param {
		module: "mnc"
		type: "SmoothL1Loss"
		param_str: "{ 'sigma': 1 }"
	}
}


layer {
	name: "accuracy_seg_ext"
	type: "Accuracy"
	bottom: "seg_cls_score_ext"
	bottom: "mask_proposal_label_ext"
	top: "accuracy_seg_ext"
}

layer {
	name: "accuracy_det_ext"
	type: "Accuracy"
	bottom: "cls_score_ext"
	bottom: "labels_ext"
	top: "accuracy_det_ext"
}

